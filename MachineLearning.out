\BOOKMARK [1][-]{section.1}{Training Models/Algorithms}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Linear Regression}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Gradient Descent}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Polynomial Regression}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{Regularized Linear Models}{section.1}% 5
\BOOKMARK [3][-]{subsubsection.1.4.1}{Ridge Regression}{subsection.1.4}% 6
\BOOKMARK [3][-]{subsubsection.1.4.2}{LASSO}{subsection.1.4}% 7
\BOOKMARK [3][-]{subsubsection.1.4.3}{Elastic Net}{subsection.1.4}% 8
\BOOKMARK [3][-]{subsubsection.1.4.4}{When to use Linear Regression, LASSO, Ridge, or Elastic Net?}{subsection.1.4}% 9
\BOOKMARK [2][-]{subsection.1.5}{Logistic Regression}{section.1}% 10
\BOOKMARK [3][-]{subsubsection.1.5.1}{Estimating Probabilities}{subsection.1.5}% 11
\BOOKMARK [3][-]{subsubsection.1.5.2}{Training and Cost Function}{subsection.1.5}% 12
\BOOKMARK [1][-]{section.2}{Classification}{}% 13
\BOOKMARK [2][-]{subsection.2.1}{MNIST}{section.2}% 14
\BOOKMARK [2][-]{subsection.2.2}{Training a Binary Classifier}{section.2}% 15
\BOOKMARK [2][-]{subsection.2.3}{Performance Measures}{section.2}% 16
\BOOKMARK [3][-]{subsubsection.2.3.1}{Measuring Accuracy Using Cross-Validation}{subsection.2.3}% 17
\BOOKMARK [3][-]{subsubsection.2.3.2}{Confusion Matrix}{subsection.2.3}% 18
\BOOKMARK [3][-]{subsubsection.2.3.3}{Precision and Recall}{subsection.2.3}% 19
\BOOKMARK [3][-]{subsubsection.2.3.4}{ROC Curve}{subsection.2.3}% 20
\BOOKMARK [2][-]{subsection.2.4}{Multiclass Classifification}{section.2}% 21
\BOOKMARK [1][-]{section.3}{Support Vector Machines}{}% 22
\BOOKMARK [2][-]{subsection.3.1}{How SVMs Work}{section.3}% 23
\BOOKMARK [2][-]{subsection.3.2}{Linear SVM Classification}{section.3}% 24
\BOOKMARK [3][-]{subsubsection.3.2.1}{Hard Margin Classification}{subsection.3.2}% 25
\BOOKMARK [3][-]{subsubsection.3.2.2}{Soft Margin Classification}{subsection.3.2}% 26
\BOOKMARK [2][-]{subsection.3.3}{Non-Linear SVM Classification}{section.3}% 27
\BOOKMARK [3][-]{subsubsection.3.3.1}{Polynomial Kernel}{subsection.3.3}% 28
\BOOKMARK [3][-]{subsubsection.3.3.2}{Gaussian RBF Kernel}{subsection.3.3}% 29
\BOOKMARK [1][-]{section.4}{Decision Trees}{}% 30
\BOOKMARK [2][-]{subsection.4.1}{Training and Visualize a Decision Tree}{section.4}% 31
\BOOKMARK [2][-]{subsection.4.2}{Making Predictions}{section.4}% 32
\BOOKMARK [2][-]{subsection.4.3}{Estimating Class Probabilities}{section.4}% 33
\BOOKMARK [2][-]{subsection.4.4}{The CART Training Algorithm}{section.4}% 34
\BOOKMARK [2][-]{subsection.4.5}{Gini Impurity or Entropy?}{section.4}% 35
\BOOKMARK [2][-]{subsection.4.6}{Regularization Hyperparameters}{section.4}% 36
\BOOKMARK [2][-]{subsection.4.7}{Regression}{section.4}% 37
\BOOKMARK [2][-]{subsection.4.8}{Instability}{section.4}% 38
\BOOKMARK [1][-]{section.5}{Random Forest}{}% 39
\BOOKMARK [2][-]{subsection.5.1}{Feature Importance}{section.5}% 40
\BOOKMARK [1][-]{section.6}{Dimensionality Reduction}{}% 41
\BOOKMARK [2][-]{subsection.6.1}{Curse of Dimensionality}{section.6}% 42
\BOOKMARK [2][-]{subsection.6.2}{Main Approaches for Dimensionality Reduction}{section.6}% 43
\BOOKMARK [3][-]{subsubsection.6.2.1}{Projection}{subsection.6.2}% 44
\BOOKMARK [3][-]{subsubsection.6.2.2}{Manifold Learning}{subsection.6.2}% 45
\BOOKMARK [2][-]{subsection.6.3}{Principal Compenents Analysis \(PCA\)}{section.6}% 46
\BOOKMARK [2][-]{subsection.6.4}{Kernel PCA}{section.6}% 47
\BOOKMARK [2][-]{subsection.6.5}{Locally Linear Embedding \(LLE\)}{section.6}% 48
\BOOKMARK [2][-]{subsection.6.6}{Other Dimensionality Reduction Techniques}{section.6}% 49
\BOOKMARK [1][-]{section.7}{Unsupervised Learning}{}% 50
\BOOKMARK [2][-]{subsection.7.1}{Clustering}{section.7}% 51
\BOOKMARK [2][-]{subsection.7.2}{Gaussian Mixtures}{section.7}% 52
